{
 "metadata": {
  "name": "",
  "signature": "sha256:5a18a56a99689f86bcec81d0389ba0383ca8f47093bf328aaf9b12a4d1386894"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Initial steps to get the data into an otu table\n",
      "=====\n",
      "The first thing that needs to be done is to run split libraries. There are currently two datasets, one for period one, and one for periods two and three. \n",
      "\n",
      "All analysis in this notebook are done with qiime 1.8.0 unless otherwise noted"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from IPython.display import FileLinks, FileLink"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The code below is not currently working as I have changed names of things.\n",
      "---------------------------------------------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#this is the mapping file that I sent to Argonne to be sequenced\n",
      "#md5 2b7d92514e0f704030acc7b4b2d52744\n",
      "run_1_ids_to_be_run_df = pd.read_csv('../../files/mapping_files/first_run_maps/first_run_ids.txt', names=['#SampleID'], index_col='#SampleID')\n",
      "\n",
      "#These are what they sent back, They are not correct.\n",
      "#md5 ba24bf3aafc54d26a7b697fd0746d926\n",
      "argonne_map_df = pd.read_csv('../../files/mapping_files/first_run_maps/first_run_map_from_argonne.txt', sep='\\t', names=['#SampleID'])\n",
      "argonne_map_df.set_index('#SampleID')\n",
      "\n",
      "#finally we arrived at this mapping file through discussion and corrections which were provided from argonne. This is not currently correct\n",
      "#md5 b900ae4cc3f453797928421c95fc789e \n",
      "run_1_map_df = pd.read_csv('../../files/mapping_files/first_run_maps/office_map_barcode_data_only_corrected.txt', index_col='#SampleID', sep='\\t')\n",
      "\n",
      "\n",
      "san_diego_df = pd.read_csv('/Users/jc33/Dropbox/caporaso_lab/office_study/mapping_files/master/san_diego_map.txt', index_col='#SampleID', sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "san_diego_df.index.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(argonne_map_df.index.values) #== len(set(argonne_map_df.index.values))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Check to see if there are any ids that are not in the valid mapping file from San Diego, \n",
      "#these should have been added but weren't\n",
      "for i in run_1_map_df.index.values:\n",
      "    if i not in san_diego_df.index.values and i.startswith('S'):\n",
      "        print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Figure out which office is missing\n",
      "for i in run_1_map_df.index.values:\n",
      "    if i[:2] + i[3:] == 'S1.3.Dr.003':\n",
      "        print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in run_1_map_df.index.values:\n",
      "    if i not in run_1_ids_to_be_run_df.index.values:\n",
      "        print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in run_1_map_df.index.values:\n",
      "    if i == 'F3C.3.Ca.001':\n",
      "        print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'F3C.3.Dr.021'[:1] + 'F3C.3.Dr.021'[3:]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#rename some of these... This list is based on emails, and logic inference from missing sample ids.\n",
      "new_row_names = {'F1W3.Dr.002':'F1W.3.Dr.002',\n",
      "                 'S1S.3.Dr.003':'S1W.3.Dr.003', 'F32.3Dr.021':'F3W.3.Dr.021', \n",
      "                 'F2W.3.C.012':'F2W.3.Ca.012'}\n",
      "run_1_map_df.rename(index=new_row_names, inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in run_1_map_df.index.values:\n",
      "    if i not in run_1_ids_to_be_run_df.index.values:\n",
      "        print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "run_1_map_df.drop(['3C.3.Dr.020', 'F3C.3.Ca.003.1'], inplace=True)\n",
      "#We have a mapping file! "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#write the mapping out to file\n",
      "run_1_map_df.to_csv('../../files/mapping_files/first_run_maps/office_map_barcode_data_only_corrected2.txt', sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!validate_mapping_file.py -m '../../files/mapping_files/first_run_maps/office_map_barcode_data_only_corrected2.txt' -o '../../files/mapping_files/first_run_maps/check_map'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FileLink('../../files/mapping_files/first_run_maps/check_map/office_map_barcode_data_only_corrected2.html')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "F3C.3.Dr.021"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# there are ids in the list of ids to be sequenced that are not in the mapping file, this is a problem.\n",
      "first_run_ids = pd.read_csv('../../files/mapping_files/first_run_maps/first_run_ids.txt', names=['#SampleID'])\n",
      "mapping_file_df = pd.read_csv('../../files/mapping_files/master_period_1-2-3_map_5182014.txt', sep='\\t')\n",
      "argonne_map_df = pd.read_csv('../../files/mapping_files/first_run_maps/first_run_map_from_argonne.txt', sep='\\t', names=['#SampleID'])\n",
      "corrected_map_df = pd.read_csv('../../files/mapping_files/office_map_barcode_data_only_corrected.txt', sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "End first run mapping analysis\n",
      "===========================\n",
      "Begin second run mapping munging\n",
      "==============================="
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "flag_map = '/Users/jc33/google_drive/thesis/analysis/files/mapping_files/flagstaff_all_ids_no_barcodes_map.txt'\n",
      "toronto_map = '/Users/jc33/google_drive/thesis/analysis/files/mapping_files/toronto_all_ids_no_barcodes_map.txt'\n",
      "san_diego_map = '/Users/jc33/google_drive/thesis/analysis/files/mapping_files/sandiego_all_ids_no_barcodes_map.txt'\n",
      "all_cities = '/Users/jc33/google_drive/thesis/analysis/files/mapping_files/all_cities_and_samples_no_barcodes_no_metadata_map.txt'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "run_2_ids_to_be_run_df = pd.read_csv('../../files/mapping_files/second_run_maps/master_seq_ids.txt', names=['#SampleID'], index_col='#SampleID')\n",
      "corrected_run_two_map = pd.read_csv('../../files/mapping_files/second_run_maps/master_map_data_5_10_14_corrected.txt', sep='\\t', index_col='#SampleID')\n",
      "corrected_run_two_map58 = pd.read_csv('../../files/mapping_files/second_run_maps/John_Chase_MappingFile_5_8_14.txt', sep='\\t', index_col='#SampleID')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IOError",
       "evalue": "File ../../files/mapping_files/second_run_maps/master_seq_ids.txt does not exist",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-12-67629fe7479b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_2_ids_to_be_run_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../files/mapping_files/second_run_maps/master_seq_ids.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'#SampleID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'#SampleID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcorrected_run_two_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../files/mapping_files/second_run_maps/master_map_data_5_10_14_corrected.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'#SampleID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcorrected_run_two_map58\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../files/mapping_files/second_run_maps/John_Chase_MappingFile_5_8_14.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'#SampleID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/jc33/.virtualenvs/qiime/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, na_fvalues, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[1;32m    463\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/jc33/.virtualenvs/qiime/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/jc33/.virtualenvs/qiime/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/jc33/.virtualenvs/qiime/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/jc33/.virtualenvs/qiime/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/jc33/.virtualenvs/qiime/lib/python2.7/site-packages/pandas/parser.so\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3136)\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;32m/Users/jc33/.virtualenvs/qiime/lib/python2.7/site-packages/pandas/parser.so\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:5767)\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;31mIOError\u001b[0m: File ../../files/mapping_files/second_run_maps/master_seq_ids.txt does not exist"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = 0 \n",
      "for i in corrected_run_two_map58.index.values:\n",
      "    if i not in run_2_ids_to_be_run_df.index.values:\n",
      "        print i\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following code is designed to add metadata to mapping files.\n",
      "================================================================\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First thing is to make sure the mapping files are formatted correctly.\n",
      "---------------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "first_run_df = pd.read_csv('/Users/jc33/google_drive/thesis/analysis/files/initial_steps/mapping_files/first_run_maps/first_run_corrected_no_metadata.txt', sep='\\t')\n",
      "second_run_df = pd.read_csv('/Users/jc33/google_drive/thesis/analysis/files/initial_steps/mapping_files/second_run_maps/second_run_corrected_map.txt', sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# I need to get the headers matching up\n",
      "second_run_df.columns = ['#SampleID', 'BarcodeSequence', 'LinkerPrimerSequence',\n",
      " 'TimeOfCollection', 'Cooler', 'Notes', 'WeekDay',\n",
      " 'DateOfCollection', 'City', 'Office', 'PlateLocation', 'Row',\n",
      " 'Surface', 'TimePoint', 'TimePointCategory', 'Description'] \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "combined_df = first_run_df.append(second_run_df)\n",
      "combined_df = combined_df.set_index('#SampleID')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cols = ['BarcodeSequence', 'LinkerPrimerSequence', 'DateOfCollection', 'TimeOfCollection', \n",
      "        'WeekDay', 'Notes', 'Cooler', 'Description'\n",
      "        ]\n",
      "\n",
      "combined_df = combined_df[cols]\n",
      "combined_df[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>BarcodeSequence</th>\n",
        "      <th>LinkerPrimerSequence</th>\n",
        "      <th>DateOfCollection</th>\n",
        "      <th>TimeOfCollection</th>\n",
        "      <th>WeekDay</th>\n",
        "      <th>Notes</th>\n",
        "      <th>Cooler</th>\n",
        "      <th>Description</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>#SampleID</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>S1F.3.Ca.023</th>\n",
        "      <td> ATGAATGCGTCC</td>\n",
        "      <td> CCGGACTACHVGGGTWTCTAAT</td>\n",
        "      <td> 7/10/2013</td>\n",
        "      <td> 16:30:00</td>\n",
        "      <td> NaN</td>\n",
        "      <td>                   JF</td>\n",
        "      <td> no_data</td>\n",
        "      <td> S1F.3.Ca.023</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>S1F.3.Ca.022</th>\n",
        "      <td> GGCCCAATATAA</td>\n",
        "      <td> CCGGACTACHVGGGTWTCTAAT</td>\n",
        "      <td>  7/8/2013</td>\n",
        "      <td> 14:50:00</td>\n",
        "      <td> NaN</td>\n",
        "      <td>                   PR</td>\n",
        "      <td> no_data</td>\n",
        "      <td> S1F.3.Ca.022</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>S1F.3.Ca.021</th>\n",
        "      <td> GTCCACTTGGAC</td>\n",
        "      <td> CCGGACTACHVGGGTWTCTAAT</td>\n",
        "      <td>  7/6/2013</td>\n",
        "      <td> 10:50:00</td>\n",
        "      <td> NaN</td>\n",
        "      <td>                   JF</td>\n",
        "      <td> no_data</td>\n",
        "      <td> S1F.3.Ca.021</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>S2C.3.Dr.003</th>\n",
        "      <td> ATCCTACGAGCA</td>\n",
        "      <td> CCGGACTACHVGGGTWTCTAAT</td>\n",
        "      <td> 5/31/2013</td>\n",
        "      <td> 12:30:00</td>\n",
        "      <td> NaN</td>\n",
        "      <td>     Time Zero, row 3</td>\n",
        "      <td> no_data</td>\n",
        "      <td> S2C.3.Dr.003</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>S2C.3.Dr.005</th>\n",
        "      <td> GATCAACCCACA</td>\n",
        "      <td> CCGGACTACHVGGGTWTCTAAT</td>\n",
        "      <td>  6/4/2013</td>\n",
        "      <td> 15:10:00</td>\n",
        "      <td> NaN</td>\n",
        "      <td> Training Pascal _PR_</td>\n",
        "      <td> no_data</td>\n",
        "      <td> S2C.3.Dr.005</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "             BarcodeSequence    LinkerPrimerSequence DateOfCollection  \\\n",
        "#SampleID                                                               \n",
        "S1F.3.Ca.023    ATGAATGCGTCC  CCGGACTACHVGGGTWTCTAAT        7/10/2013   \n",
        "S1F.3.Ca.022    GGCCCAATATAA  CCGGACTACHVGGGTWTCTAAT         7/8/2013   \n",
        "S1F.3.Ca.021    GTCCACTTGGAC  CCGGACTACHVGGGTWTCTAAT         7/6/2013   \n",
        "S2C.3.Dr.003    ATCCTACGAGCA  CCGGACTACHVGGGTWTCTAAT        5/31/2013   \n",
        "S2C.3.Dr.005    GATCAACCCACA  CCGGACTACHVGGGTWTCTAAT         6/4/2013   \n",
        "\n",
        "             TimeOfCollection WeekDay                 Notes   Cooler  \\\n",
        "#SampleID                                                              \n",
        "S1F.3.Ca.023         16:30:00     NaN                    JF  no_data   \n",
        "S1F.3.Ca.022         14:50:00     NaN                    PR  no_data   \n",
        "S1F.3.Ca.021         10:50:00     NaN                    JF  no_data   \n",
        "S2C.3.Dr.003         12:30:00     NaN      Time Zero, row 3  no_data   \n",
        "S2C.3.Dr.005         15:10:00     NaN  Training Pascal _PR_  no_data   \n",
        "\n",
        "               Description  \n",
        "#SampleID                   \n",
        "S1F.3.Ca.023  S1F.3.Ca.023  \n",
        "S1F.3.Ca.022  S1F.3.Ca.022  \n",
        "S1F.3.Ca.021  S1F.3.Ca.021  \n",
        "S2C.3.Dr.003  S2C.3.Dr.003  \n",
        "S2C.3.Dr.005  S2C.3.Dr.005  "
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We now have a combined mapping file that only contains columns with information that is NOT inherent in the ID"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Get the metadata that we can from the city maps\n",
      "------------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "flagstaff_df = pd.read_csv('/Users/jc33/google_drive/thesis/analysis/files/initial_steps/mapping_files/flagstaff_all_ids_no_barcodes_map.txt', sep='\\t', index_col='#SampleID')\n",
      "san_diego_df = pd.read_csv('/Users/jc33/google_drive/thesis/analysis/files/initial_steps/mapping_files/sandiego_all_ids_no_barcodes_map.txt', sep='\\t', index_col='#SampleID')\n",
      "toronto_df = pd.read_csv('/Users/jc33/google_drive/thesis/analysis/files/initial_steps/mapping_files/toronto_all_ids_no_barcodes_map.txt', sep='\\t', index_col='#SampleID')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "flagstaff_df.columns = ['DateOfCollection', 'TimeOfCollection', 'Notes', 'WeekDay']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def correct_time(time):\n",
      "    time = str(time)\n",
      "    try:\n",
      "        int(time[0])\n",
      "    except: \n",
      "        time = 'no data'\n",
      "    else:\n",
      "        if ':' in time:\n",
      "            pass\n",
      "        else:\n",
      "            time = time[:-2] + ':' + time[-2:] + ':00'\n",
      "    return time\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "flagstaff_df['TimeOfCollection'] = flagstaff_df['TimeOfCollection'].apply(correct_time)\n",
      "flagstaff_df['Cooler'] = np.nan"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "san_diego_df.columns = ['DateOfCollection', 'TimeOfCollection', 'Notes', 'WeekDay']\n",
      "san_diego_df['Cooler'] = np.nan"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "toronto_df.columns = ['DateOfCollection', 'TimeOfCollection', 'Notes', 'Cooler', 'WeekDay']\n",
      "toronto_df = toronto_df[['DateOfCollection', 'TimeOfCollection', 'Notes','WeekDay', 'Cooler']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "flag_toront_no_barcodes_df = flagstaff_df.append(toronto_df)\n",
      "all_cities_no_barcodes_df = flag_toront_no_barcodes_df.append(san_diego_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_cities_no_barcodes_df.ix[['S1F.3.Ca.022', 'S1C.3.Ce.001']]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>DateOfCollection</th>\n",
        "      <th>TimeOfCollection</th>\n",
        "      <th>Notes</th>\n",
        "      <th>WeekDay</th>\n",
        "      <th>Cooler</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>#SampleID</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>S1F.3.Ca.022</th>\n",
        "      <td>  7/8/2013</td>\n",
        "      <td>          14:50:00</td>\n",
        "      <td>                PR</td>\n",
        "      <td>    Monday</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>S1C.3.Ce.001</th>\n",
        "      <td> 5/29/2013</td>\n",
        "      <td> Time not recorded</td>\n",
        "      <td> pre-sterilization</td>\n",
        "      <td> Wednesday</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "             DateOfCollection   TimeOfCollection              Notes  \\\n",
        "#SampleID                                                             \n",
        "S1F.3.Ca.022         7/8/2013           14:50:00                 PR   \n",
        "S1C.3.Ce.001        5/29/2013  Time not recorded  pre-sterilization   \n",
        "\n",
        "                WeekDay  Cooler  \n",
        "#SampleID                        \n",
        "S1F.3.Ca.022     Monday     NaN  \n",
        "S1C.3.Ce.001  Wednesday     NaN  "
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#There was a duplicate id in the toronto map that was causing some problems\n",
      "# # print combined_df.columns\n",
      "print len(combined_df.index)\n",
      "print len(all_cities_no_barcodes_df.ix[combined_df.index])\n",
      "# this = all_cities_no_barcodes_df.ix[combined_df.index]['TimeOfCollection']\n",
      "# print len(this)\n",
      "# print len(combined_df['TimeOfCollection'])\n",
      "# for i in this:\n",
      "#     print i \n",
      "print len(all_cities_no_barcodes_df.ix[combined_df.index].index)\n",
      "for i in all_cities_no_barcodes_df.ix[combined_df.index].index:\n",
      "    if i not in combined_df.index:\n",
      "        print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1605\n",
        "1605\n",
        "1605\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import collections\n",
      "print [x for x, y in collections.Counter(all_cities_no_barcodes_df.ix[combined_df.index].index).items() if y > 1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[]\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "toc = all_cities_no_barcodes_df.ix[combined_df.index][['DateOfCollection', 'TimeOfCollection', 'Notes','WeekDay', 'Cooler']]\n",
      "combined_df[['DateOfCollection', 'TimeOfCollection', 'Notes','WeekDay', 'Cooler']] = all_cities_no_barcodes_df.ix[combined_df.index][['DateOfCollection', 'TimeOfCollection', 'Notes','WeekDay', 'Cooler']]\n",
      "combined_df[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>BarcodeSequence</th>\n",
        "      <th>LinkerPrimerSequence</th>\n",
        "      <th>DateOfCollection</th>\n",
        "      <th>TimeOfCollection</th>\n",
        "      <th>WeekDay</th>\n",
        "      <th>Notes</th>\n",
        "      <th>Cooler</th>\n",
        "      <th>Description</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>#SampleID</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>S1F.3.Ca.023</th>\n",
        "      <td> ATGAATGCGTCC</td>\n",
        "      <td> CCGGACTACHVGGGTWTCTAAT</td>\n",
        "      <td> 7/10/2013</td>\n",
        "      <td> 16:30:00</td>\n",
        "      <td> Wednesday</td>\n",
        "      <td>                   JF</td>\n",
        "      <td>NaN</td>\n",
        "      <td> S1F.3.Ca.023</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>S1F.3.Ca.022</th>\n",
        "      <td> GGCCCAATATAA</td>\n",
        "      <td> CCGGACTACHVGGGTWTCTAAT</td>\n",
        "      <td>  7/8/2013</td>\n",
        "      <td> 14:50:00</td>\n",
        "      <td>    Monday</td>\n",
        "      <td>                   PR</td>\n",
        "      <td>NaN</td>\n",
        "      <td> S1F.3.Ca.022</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>S1F.3.Ca.021</th>\n",
        "      <td> GTCCACTTGGAC</td>\n",
        "      <td> CCGGACTACHVGGGTWTCTAAT</td>\n",
        "      <td>  7/6/2013</td>\n",
        "      <td> 10:50:00</td>\n",
        "      <td>  Saturday</td>\n",
        "      <td>                   JF</td>\n",
        "      <td>NaN</td>\n",
        "      <td> S1F.3.Ca.021</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>S2C.3.Dr.003</th>\n",
        "      <td> ATCCTACGAGCA</td>\n",
        "      <td> CCGGACTACHVGGGTWTCTAAT</td>\n",
        "      <td> 5/31/2013</td>\n",
        "      <td> 12:30:00</td>\n",
        "      <td>    Friday</td>\n",
        "      <td>     Time Zero, row 3</td>\n",
        "      <td>NaN</td>\n",
        "      <td> S2C.3.Dr.003</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>S2C.3.Dr.005</th>\n",
        "      <td> GATCAACCCACA</td>\n",
        "      <td> CCGGACTACHVGGGTWTCTAAT</td>\n",
        "      <td>  6/4/2013</td>\n",
        "      <td> 15:10:00</td>\n",
        "      <td>   Tuesday</td>\n",
        "      <td> Training Pascal (PR)</td>\n",
        "      <td>NaN</td>\n",
        "      <td> S2C.3.Dr.005</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "             BarcodeSequence    LinkerPrimerSequence DateOfCollection  \\\n",
        "#SampleID                                                               \n",
        "S1F.3.Ca.023    ATGAATGCGTCC  CCGGACTACHVGGGTWTCTAAT        7/10/2013   \n",
        "S1F.3.Ca.022    GGCCCAATATAA  CCGGACTACHVGGGTWTCTAAT         7/8/2013   \n",
        "S1F.3.Ca.021    GTCCACTTGGAC  CCGGACTACHVGGGTWTCTAAT         7/6/2013   \n",
        "S2C.3.Dr.003    ATCCTACGAGCA  CCGGACTACHVGGGTWTCTAAT        5/31/2013   \n",
        "S2C.3.Dr.005    GATCAACCCACA  CCGGACTACHVGGGTWTCTAAT         6/4/2013   \n",
        "\n",
        "             TimeOfCollection    WeekDay                 Notes  Cooler  \\\n",
        "#SampleID                                                                \n",
        "S1F.3.Ca.023         16:30:00  Wednesday                    JF     NaN   \n",
        "S1F.3.Ca.022         14:50:00     Monday                    PR     NaN   \n",
        "S1F.3.Ca.021         10:50:00   Saturday                    JF     NaN   \n",
        "S2C.3.Dr.003         12:30:00     Friday      Time Zero, row 3     NaN   \n",
        "S2C.3.Dr.005         15:10:00    Tuesday  Training Pascal (PR)     NaN   \n",
        "\n",
        "               Description  \n",
        "#SampleID                   \n",
        "S1F.3.Ca.023  S1F.3.Ca.023  \n",
        "S1F.3.Ca.022  S1F.3.Ca.022  \n",
        "S1F.3.Ca.021  S1F.3.Ca.021  \n",
        "S2C.3.Dr.003  S2C.3.Dr.003  \n",
        "S2C.3.Dr.005  S2C.3.Dr.005  "
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "combined_df[-5:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>BarcodeSequence</th>\n",
        "      <th>LinkerPrimerSequence</th>\n",
        "      <th>DateOfCollection</th>\n",
        "      <th>TimeOfCollection</th>\n",
        "      <th>WeekDay</th>\n",
        "      <th>Notes</th>\n",
        "      <th>Cooler</th>\n",
        "      <th>Description</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>#SampleID</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>S2F.3.Ce.041</th>\n",
        "      <td> TTAGGCAGGTTC</td>\n",
        "      <td> CCGGACTACHVGGGTWTCTAAT</td>\n",
        "      <td> 11/1/2013</td>\n",
        "      <td> 13:55:00</td>\n",
        "      <td> Friday</td>\n",
        "      <td>  JF</td>\n",
        "      <td>NaN</td>\n",
        "      <td> S2F.3.Ce.041</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>F1W.2.Ca.040</th>\n",
        "      <td> GGTCCCGAAATT</td>\n",
        "      <td> CCGGACTACHVGGGTWTCTAAT</td>\n",
        "      <td> 11/4/2013</td>\n",
        "      <td> 20:15:00</td>\n",
        "      <td> Monday</td>\n",
        "      <td> NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td> F1W.2.Ca.040</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>F1W.2.Ca.041</th>\n",
        "      <td> ACCTGGGAATAT</td>\n",
        "      <td> CCGGACTACHVGGGTWTCTAAT</td>\n",
        "      <td>  1/6/2014</td>\n",
        "      <td> 17:20:00</td>\n",
        "      <td> Monday</td>\n",
        "      <td> NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td> F1W.2.Ca.041</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>T2W.2.Ca.059</th>\n",
        "      <td> ATCGAATCGAGT</td>\n",
        "      <td> CCGGACTACHVGGGTWTCTAAT</td>\n",
        "      <td> 2/17/2014</td>\n",
        "      <td>  9:27:00</td>\n",
        "      <td> Monday</td>\n",
        "      <td>  JS</td>\n",
        "      <td>NaN</td>\n",
        "      <td> T2W.2.Ca.059</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>T2W.2.Ca.050</th>\n",
        "      <td> GTCGACAGAGGA</td>\n",
        "      <td> CCGGACTACHVGGGTWTCTAAT</td>\n",
        "      <td> 1/27/2014</td>\n",
        "      <td> 11:51:00</td>\n",
        "      <td> Monday</td>\n",
        "      <td>  MZ</td>\n",
        "      <td>NaN</td>\n",
        "      <td> T2W.2.Ca.050</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "             BarcodeSequence    LinkerPrimerSequence DateOfCollection  \\\n",
        "#SampleID                                                               \n",
        "S2F.3.Ce.041    TTAGGCAGGTTC  CCGGACTACHVGGGTWTCTAAT        11/1/2013   \n",
        "F1W.2.Ca.040    GGTCCCGAAATT  CCGGACTACHVGGGTWTCTAAT        11/4/2013   \n",
        "F1W.2.Ca.041    ACCTGGGAATAT  CCGGACTACHVGGGTWTCTAAT         1/6/2014   \n",
        "T2W.2.Ca.059    ATCGAATCGAGT  CCGGACTACHVGGGTWTCTAAT        2/17/2014   \n",
        "T2W.2.Ca.050    GTCGACAGAGGA  CCGGACTACHVGGGTWTCTAAT        1/27/2014   \n",
        "\n",
        "             TimeOfCollection WeekDay Notes  Cooler   Description  \n",
        "#SampleID                                                          \n",
        "S2F.3.Ce.041         13:55:00  Friday    JF     NaN  S2F.3.Ce.041  \n",
        "F1W.2.Ca.040         20:15:00  Monday   NaN     NaN  F1W.2.Ca.040  \n",
        "F1W.2.Ca.041         17:20:00  Monday   NaN     NaN  F1W.2.Ca.041  \n",
        "T2W.2.Ca.059          9:27:00  Monday    JS     NaN  T2W.2.Ca.059  \n",
        "T2W.2.Ca.050         11:51:00  Monday    MZ     NaN  T2W.2.Ca.050  "
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print san_diego_df['DateOfCollection']['S2C.3.Dr.004']\n",
      "print combined_df['DateOfCollection']['S2C.3.Dr.004']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "6/2/2013\n",
        "6/2/2013\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Well that sucked! Now we need to add the metadata from the ids\n",
      "---------------------------------------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "id_dictionary = {'City':{'S':'san_diego', 'F':'flagstaff', 'T':'toronto'},\n",
      "                 'PlateLocation':{'F':'floor', 'W':'wall', 'C':'ceiling'},\n",
      "                 'Material':{'Ca':'carpet', 'Dr':'drywall', 'Ce':'ceiling_tile'}, \n",
      "                 'Period':{}}\n",
      "\n",
      "\n",
      "combined_df['City'] = [id_dictionary['City'][key] if key in id_dictionary['City'] else np.nan for key in (combined_df.index.to_series().str[0])]\n",
      "combined_df['PlateLocation'] = [id_dictionary['PlateLocation'][key] if key in id_dictionary['PlateLocation'] else np.nan for key in (combined_df.index.to_series().str[2])]\n",
      "combined_df['Material'] = [id_dictionary['Material'][key] if key in id_dictionary['Material'] else np.nan for key in (combined_df.index.to_series().str[6:8])]\n",
      "combined_df['OfficeNumber'] = (combined_df.index.to_series().str[1])\n",
      "combined_df['Row'] = (combined_df.index.to_series().str[4])\n",
      "combined_df['Event'] = combined_df.index.to_series().str[9:12].astype(int)\n",
      "\n",
      "\n",
      "combined_df['OfficeNumberPlateLocation'] = combined_df['OfficeNumber'] + '_' + combined_df['PlateLocation']\n",
      "combined_df['CityOfficeNumber'] = combined_df['City'] + '_' + combined_df['OfficeNumber']\n",
      "combined_df['CityOfficeNumberLocation'] = combined_df['City'] + '_' + combined_df['OfficeNumber'] + '_' + combined_df['PlateLocation']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "combined_df = combined_df.drop(['blankswab5', 'blankswab1', 'blankswab2', 'blankswab3' , 'blankswab4'])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "combined_df[combined_df['Event'] == 22][:5]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>BarcodeSequence</th>\n",
        "      <th>LinkerPrimerSequence</th>\n",
        "      <th>DateOfCollection</th>\n",
        "      <th>TimeOfCollection</th>\n",
        "      <th>WeekDay</th>\n",
        "      <th>Notes</th>\n",
        "      <th>Cooler</th>\n",
        "      <th>Description</th>\n",
        "      <th>City</th>\n",
        "      <th>PlateLocation</th>\n",
        "      <th>Material</th>\n",
        "      <th>OfficeNumber</th>\n",
        "      <th>Row</th>\n",
        "      <th>Event</th>\n",
        "      <th>OfficeNumberPlateLocation</th>\n",
        "      <th>CityOfficeNumber</th>\n",
        "      <th>CityOfficeNumberLocation</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>#SampleID</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>S1F.3.Ca.022</th>\n",
        "      <td> GGCCCAATATAA</td>\n",
        "      <td> CCGGACTACHVGGGTWTCTAAT</td>\n",
        "      <td> 7/8/2013</td>\n",
        "      <td> 14:50:00</td>\n",
        "      <td> Monday</td>\n",
        "      <td> PR</td>\n",
        "      <td>NaN</td>\n",
        "      <td> S1F.3.Ca.022</td>\n",
        "      <td> san_diego</td>\n",
        "      <td>   floor</td>\n",
        "      <td>       carpet</td>\n",
        "      <td> 1</td>\n",
        "      <td> 3</td>\n",
        "      <td> 22</td>\n",
        "      <td>   1_floor</td>\n",
        "      <td> san_diego_1</td>\n",
        "      <td>   san_diego_1_floor</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>S1W.3.Ce.022</th>\n",
        "      <td> TTGTATGACAGG</td>\n",
        "      <td> CCGGACTACHVGGGTWTCTAAT</td>\n",
        "      <td> 7/8/2013</td>\n",
        "      <td> 14:50:00</td>\n",
        "      <td> Monday</td>\n",
        "      <td> PR</td>\n",
        "      <td>NaN</td>\n",
        "      <td> S1W.3.Ce.022</td>\n",
        "      <td> san_diego</td>\n",
        "      <td>    wall</td>\n",
        "      <td> ceiling_tile</td>\n",
        "      <td> 1</td>\n",
        "      <td> 3</td>\n",
        "      <td> 22</td>\n",
        "      <td>    1_wall</td>\n",
        "      <td> san_diego_1</td>\n",
        "      <td>    san_diego_1_wall</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>S1C.3.Ce.022</th>\n",
        "      <td> CATAGCTCGGTC</td>\n",
        "      <td> CCGGACTACHVGGGTWTCTAAT</td>\n",
        "      <td> 7/8/2013</td>\n",
        "      <td> 14:50:00</td>\n",
        "      <td> Monday</td>\n",
        "      <td> PR</td>\n",
        "      <td>NaN</td>\n",
        "      <td> S1C.3.Ce.022</td>\n",
        "      <td> san_diego</td>\n",
        "      <td> ceiling</td>\n",
        "      <td> ceiling_tile</td>\n",
        "      <td> 1</td>\n",
        "      <td> 3</td>\n",
        "      <td> 22</td>\n",
        "      <td> 1_ceiling</td>\n",
        "      <td> san_diego_1</td>\n",
        "      <td> san_diego_1_ceiling</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>S2C.3.Dr.022</th>\n",
        "      <td> GCAAATCAGCCT</td>\n",
        "      <td> CCGGACTACHVGGGTWTCTAAT</td>\n",
        "      <td> 7/8/2013</td>\n",
        "      <td> 14:10:00</td>\n",
        "      <td> Monday</td>\n",
        "      <td> PR</td>\n",
        "      <td>NaN</td>\n",
        "      <td> S2C.3.Dr.022</td>\n",
        "      <td> san_diego</td>\n",
        "      <td> ceiling</td>\n",
        "      <td>      drywall</td>\n",
        "      <td> 2</td>\n",
        "      <td> 3</td>\n",
        "      <td> 22</td>\n",
        "      <td> 2_ceiling</td>\n",
        "      <td> san_diego_2</td>\n",
        "      <td> san_diego_2_ceiling</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>S3F.3.Ce.022</th>\n",
        "      <td> GAAGATCTATCG</td>\n",
        "      <td> CCGGACTACHVGGGTWTCTAAT</td>\n",
        "      <td> 7/8/2013</td>\n",
        "      <td> 14:30:00</td>\n",
        "      <td> Monday</td>\n",
        "      <td> PR</td>\n",
        "      <td>NaN</td>\n",
        "      <td> S3F.3.Ce.022</td>\n",
        "      <td> san_diego</td>\n",
        "      <td>   floor</td>\n",
        "      <td> ceiling_tile</td>\n",
        "      <td> 3</td>\n",
        "      <td> 3</td>\n",
        "      <td> 22</td>\n",
        "      <td>   3_floor</td>\n",
        "      <td> san_diego_3</td>\n",
        "      <td>   san_diego_3_floor</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "             BarcodeSequence    LinkerPrimerSequence DateOfCollection  \\\n",
        "#SampleID                                                               \n",
        "S1F.3.Ca.022    GGCCCAATATAA  CCGGACTACHVGGGTWTCTAAT         7/8/2013   \n",
        "S1W.3.Ce.022    TTGTATGACAGG  CCGGACTACHVGGGTWTCTAAT         7/8/2013   \n",
        "S1C.3.Ce.022    CATAGCTCGGTC  CCGGACTACHVGGGTWTCTAAT         7/8/2013   \n",
        "S2C.3.Dr.022    GCAAATCAGCCT  CCGGACTACHVGGGTWTCTAAT         7/8/2013   \n",
        "S3F.3.Ce.022    GAAGATCTATCG  CCGGACTACHVGGGTWTCTAAT         7/8/2013   \n",
        "\n",
        "             TimeOfCollection WeekDay Notes  Cooler   Description       City  \\\n",
        "#SampleID                                                                      \n",
        "S1F.3.Ca.022         14:50:00  Monday    PR     NaN  S1F.3.Ca.022  san_diego   \n",
        "S1W.3.Ce.022         14:50:00  Monday    PR     NaN  S1W.3.Ce.022  san_diego   \n",
        "S1C.3.Ce.022         14:50:00  Monday    PR     NaN  S1C.3.Ce.022  san_diego   \n",
        "S2C.3.Dr.022         14:10:00  Monday    PR     NaN  S2C.3.Dr.022  san_diego   \n",
        "S3F.3.Ce.022         14:30:00  Monday    PR     NaN  S3F.3.Ce.022  san_diego   \n",
        "\n",
        "             PlateLocation      Material OfficeNumber Row  Event  \\\n",
        "#SampleID                                                          \n",
        "S1F.3.Ca.022         floor        carpet            1   3     22   \n",
        "S1W.3.Ce.022          wall  ceiling_tile            1   3     22   \n",
        "S1C.3.Ce.022       ceiling  ceiling_tile            1   3     22   \n",
        "S2C.3.Dr.022       ceiling       drywall            2   3     22   \n",
        "S3F.3.Ce.022         floor  ceiling_tile            3   3     22   \n",
        "\n",
        "             OfficeNumberPlateLocation CityOfficeNumber  \\\n",
        "#SampleID                                                 \n",
        "S1F.3.Ca.022                   1_floor      san_diego_1   \n",
        "S1W.3.Ce.022                    1_wall      san_diego_1   \n",
        "S1C.3.Ce.022                 1_ceiling      san_diego_1   \n",
        "S2C.3.Dr.022                 2_ceiling      san_diego_2   \n",
        "S3F.3.Ce.022                   3_floor      san_diego_3   \n",
        "\n",
        "             CityOfficeNumberLocation  \n",
        "#SampleID                              \n",
        "S1F.3.Ca.022        san_diego_1_floor  \n",
        "S1W.3.Ce.022         san_diego_1_wall  \n",
        "S1C.3.Ce.022      san_diego_1_ceiling  \n",
        "S2C.3.Dr.022      san_diego_2_ceiling  \n",
        "S3F.3.Ce.022        san_diego_3_floor  "
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#This particular ID was updated manually and I forgot to change the data fpr until now.\n",
      "combined_df['DaysSinceEpoch']['T3W.3.Ce.022'] = 15894.0 \n",
      "combined_df['Season']['T3W.3.Ce.022'] = 'summer' \n",
      "combined_df['Event']['T3W.3.Ce.022'] = 22\n",
      "combined_df['Period']['T3W.3.Ce.022'] = 1 \n",
      "combined_df['DateOfCollection']['T3W.3.Ce.022'] = '7/8/2013'\n",
      "combined_df['WeekDay']['T3W.3.Ce.022'] = 'Monday'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "combined_df['DaysSinceEpoch'] = combined_df['DaysSinceEpoch'].astype(str)\n",
      "combined_df = combined_df[combined_df['DaysSinceEpoch'] != 'nan']\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from datetime import datetime\n",
      "\n",
      "def compute_days_since_epoch(day, month, year):\n",
      "    \"\"\" pass day, month, year to compute days since epoch (1/1/1970)\n",
      "        Note that full years should always be provided: 09 is a\n",
      "        different year than 2009!\n",
      "    \"\"\"\n",
      "    d = datetime(int(year), int(month), int(day))\n",
      "    epoch = datetime.utcfromtimestamp(0)\n",
      "    return (d - epoch).days\n",
      "\n",
      "def get_period(epoch):\n",
      "    try:\n",
      "        epoch = int(epoch)\n",
      "        if epoch < 15971:\n",
      "            period = 1\n",
      "        elif epoch >= 15971 and epoch <= 16075:\n",
      "            period = 2\n",
      "        elif epoch >= 16076:\n",
      "            period = 3\n",
      "        return period\n",
      "    except:\n",
      "#         print epoch\n",
      "        return np.nan\n",
      "        \n",
      "def get_days_since_epoch(date):\n",
      "#     compute_days_since_epoch(day, month, year)\n",
      "    try:\n",
      "        month, day, year = date.split('/')\n",
      "        epoch = compute_days_since_epoch(day, month, year)\n",
      "        return epoch\n",
      "    except:\n",
      "        print date\n",
      "        return np.nan\n",
      "    \n",
      "def get_season(period):\n",
      "    try:\n",
      "        period = int(period)\n",
      "        if period == 1:\n",
      "            season = 'summer'\n",
      "        elif period == 2:\n",
      "            season = 'fall'\n",
      "        elif period == 3:\n",
      "            season = 'winter'\n",
      "        else:\n",
      "            raise valueError('somethings not right')\n",
      "        return season\n",
      "    except:\n",
      "#         print period\n",
      "        return np.nan\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "combined_df['DaysSinceEpoch'] = combined_df['DateOfCollection'].apply(get_days_since_epoch)\n",
      "combined_df['Period'] = combined_df['DaysSinceEpoch'].apply(get_period)\n",
      "combined_df['Season'] =  combined_df['Period'].apply(get_season)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "combined_df.to_csv('/Users/jc33/google_drive/thesis/analysis/files/initial_steps/mapping_files/periods1-2-3_all_data_barcodes_map141108.txt', sep='\\t', na_rep='no_data')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!validate_mapping_file.py -m '/Users/jc33/google_drive/thesis/analysis/files/mapping_files/periods1-2-3_all_data_barcodes_map.txt' -o '/Users/jc33/google_drive/thesis/analysis/files/mapping_files/check_map'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Errors and/or warnings detected in mapping file.  Please check the log and html file for details.\r\n"
       ]
      }
     ],
     "prompt_number": 291
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}