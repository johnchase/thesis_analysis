{
 "metadata": {
  "name": "",
  "signature": "sha256:54d2e392ca91626619dae4b8b9a8a0e37bb9a8212442aedc0a932c0bb1a2a7de"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Initial steps to get the data into an otu table\n",
      "=====\n",
      "The first thing that needs to be done is to run split libraries. There are currently two datasets, one for period one, and one for periods two and three. \n",
      "\n",
      "All analysis in this notebook are done with qiime 1.8.0 unless otherwise noted"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from IPython.display import FileLinks, FileLink"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 148
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#this is the mapping file that I sent to Argonne to be sequenced\n",
      "#md5 2b7d92514e0f704030acc7b4b2d52744\n",
      "run_1_ids_to_be_run_df = pd.read_csv('../../files/mapping_files/first_run_maps/first_run_ids.txt', names=['#SampleID'], index_col='#SampleID')\n",
      "\n",
      "#These are what they sent back, They are not correct.\n",
      "#md5 ba24bf3aafc54d26a7b697fd0746d926\n",
      "argonne_map_df = pd.read_csv('../../files/mapping_files/first_run_maps/first_run_map_from_argonne.txt', sep='\\t', names=['#SampleID'])\n",
      "argonne_map_df.set_index('#SampleID')\n",
      "\n",
      "#finally we arrived at this mapping file through discussion and corrections which were provided from argonne. This is not currently correct\n",
      "#md5 b900ae4cc3f453797928421c95fc789e \n",
      "run_1_map_df = pd.read_csv('../../files/mapping_files/first_run_maps/office_map_barcode_data_only_corrected.txt', index_col='#SampleID', sep='\\t')\n",
      "\n",
      "\n",
      "san_diego_df = pd.read_csv('/Users/jc33/Dropbox/caporaso_lab/office_study/mapping_files/master/san_diego_map.txt', index_col='#SampleID', sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 150
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "san_diego_df.index.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 151,
       "text": [
        "array(['S1C.3.Ca.001', 'S1C.3.Ce.001', 'S1C.3.Dr.001', ..., 'S3W.2.Ca.041',\n",
        "       'S3W.2.Ce.041', 'S3W.2.Dr.041'], dtype=object)"
       ]
      }
     ],
     "prompt_number": 151
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(argonne_map_df.index.values) #== len(set(argonne_map_df.index.values))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 152,
       "text": [
        "769"
       ]
      }
     ],
     "prompt_number": 152
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Check to see if there are any ids that are not in the valid mapping file from San Diego, \n",
      "#these should have been added but weren't\n",
      "for i in run_1_map_df.index.values:\n",
      "    if i not in san_diego_df.index.values and i.startswith('S'):\n",
      "        print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "S1S.3.Dr.003\n"
       ]
      }
     ],
     "prompt_number": 153
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Figure out which office is missing\n",
      "for i in run_1_map_df.index.values:\n",
      "    if i[:2] + i[3:] == 'S1.3.Dr.003':\n",
      "        print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "S1C.3.Dr.003\n",
        "S1S.3.Dr.003\n",
        "S1F.3.Dr.003\n"
       ]
      }
     ],
     "prompt_number": 154
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in run_1_map_df.index.values:\n",
      "    if i not in run_1_ids_to_be_run_df.index.values:\n",
      "        print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "F32.3Dr.021\n",
        "blankswab1\n",
        "blankswab3\n",
        "blankswab2\n",
        "S1S.3.Dr.003\n",
        "F1W3.Dr.002\n",
        "S1F.2.Ce.003\n",
        "3C.3.Dr.020\n",
        "blankswab5\n",
        "blankswab4\n",
        "F3F.2.Dr.001\n",
        "F3C.3.Ca.003.1\n",
        "F2W.3.C.012\n"
       ]
      }
     ],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in run_1_map_df.index.values:\n",
      "    if i == 'F3C.3.Ca.001':\n",
      "        print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "F3C.3.Ca.001\n"
       ]
      }
     ],
     "prompt_number": 174
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'F3C.3.Dr.021'[:1] + 'F3C.3.Dr.021'[3:]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 167,
       "text": [
        "'F.3.Dr.021'"
       ]
      }
     ],
     "prompt_number": 167
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#rename some of these... This list is based on emails, and logic inference from missing sample ids.\n",
      "new_row_names = {'F1W3.Dr.002':'F1W.3.Dr.002',\n",
      "                 'S1S.3.Dr.003':'S1W.3.Dr.003', 'F32.3Dr.021':'F3W.3.Dr.021', \n",
      "                 'F2W.3.C.012':'F2W.3.Ca.012'}\n",
      "run_1_map_df.rename(index=new_row_names, inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 175
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in run_1_map_df.index.values:\n",
      "    if i not in run_1_ids_to_be_run_df.index.values:\n",
      "        print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "blankswab1\n",
        "blankswab3\n",
        "blankswab2\n",
        "S1F.2.Ce.003\n",
        "blankswab5\n",
        "blankswab4\n",
        "F3F.2.Dr.001\n"
       ]
      }
     ],
     "prompt_number": 176
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "run_1_map_df.drop(['3C.3.Dr.020', 'F3C.3.Ca.003.1'], inplace=True)\n",
      "#We have a mapping file! "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 178
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#write the mapping out to file\n",
      "run_1_map_df.to_csv('../../files/mapping_files/first_run_maps/office_map_barcode_data_only_corrected2.txt', sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 179
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!validate_mapping_file.py -m '../../files/mapping_files/first_run_maps/office_map_barcode_data_only_corrected2.txt' -o '../../files/mapping_files/first_run_maps/check_map'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Errors and/or warnings detected in mapping file.  Please check the log and html file for details.\r\n"
       ]
      }
     ],
     "prompt_number": 180
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FileLink('../../files/mapping_files/first_run_maps/check_map/office_map_barcode_data_only_corrected2.html')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<a href='../../files/mapping_files/first_run_maps/check_map/office_map_barcode_data_only_corrected2.html' target='_blank'>../../files/mapping_files/first_run_maps/check_map/office_map_barcode_data_only_corrected2.html</a><br>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 149,
       "text": [
        "/Users/jc33/google_drive/thesis/analysis/files/mapping_files/first_run_maps/check_map/office_map_barcode_data_only_corrected2.html"
       ]
      }
     ],
     "prompt_number": 149
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "F3C.3.Dr.021"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# there are ids in the list of ids to be sequenced that are not in the mapping file, this is a problem.\n",
      "first_run_ids = pd.read_csv('../../files/mapping_files/first_run_maps/first_run_ids.txt', names=['#SampleID'])\n",
      "mapping_file_df = pd.read_csv('../../files/mapping_files/master_period_1-2-3_map_5182014.txt', sep='\\t')\n",
      "argonne_map_df = pd.read_csv('../../files/mapping_files/first_run_maps/first_run_map_from_argonne.txt', sep='\\t', names=['#SampleID'])\n",
      "corrected_map_df = pd.read_csv('../../files/mapping_files/office_map_barcode_data_only_corrected.txt', sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!md5 '../../files/mapping_files/first_run_maps/office_map_barcode_data_only_corrected.txt'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "MD5 (../../files/mapping_files/first_run_maps/office_map_barcode_data_only_corrected.txt) = b900ae4cc3f453797928421c95fc789e\r\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "argonne_map_df['#SampleID'] = map(str.upper, argonne_map_df['#SampleID'])\n",
      "mapping_file_df['#SampleID'] = map(str.upper, mapping_file_df['#SampleID'])\n",
      "first_run_ids['#SampleID'] = map(str.upper, first_run_ids['#SampleID'])\n",
      "corrected_map_df['#SampleID'] = map(str.upper, corrected_map_df['#SampleID'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "first_ids = np.array(first_run_ids['#SampleID'])\n",
      "argonne_map_ids = np.array(argonne_map_df['#SampleID'])\n",
      "corrected_map_ds = np.array(corrected_map_df['#SampleID'])\n",
      "for i in argonne_map_ids:\n",
      "    if i not in corrected_map_ds:\n",
      "        print i "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DESCRIPTION\n",
        "BLANK SWAB\n",
        "BLANK SWAB\n",
        "BLANK SWAB\n",
        "BLANK SWAB\n",
        "BLANK.SWAB\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#First run split libraries on the two datasets\n",
      "!split_libraries_fastq.py -i /scratch/jc33/run_1_fastqs/Undetermined_S0_L001_R1_001.fastq -m /scratch/jc33/master_period_1-2-3_map_5182014.txt -o split_lib_out --barcode_type 12 -b /scratch/jc33/run_1_fastqsUndetermined_S0_L001_I1_001.fastq --rev_comp_mapping_barcodes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Usage: split_libraries_fastq.py [options] {-i/--sequence_read_fps SEQUENCE_READ_FPS -o/--output_dir OUTPUT_DIR}\r\n",
        "\r\n",
        "[] indicates optional input (order unimportant)\r\n",
        "{} indicates required input (order unimportant)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "Example usage: \r\n",
        "Print help message and exit\r\n",
        " split_libraries_fastq.py -h\r\n",
        "\r\n",
        "Demultiplex and quality filter (at Phred >= Q20) one lane of Illumina fastq data and write results to ./slout_q20.: \r\n",
        " split_libraries_fastq.py -i lane1_read1.fastq.gz -b lane1_barcode.fastq.gz --rev_comp_mapping_barcodes -o slout_q20/ -m map.txt -q 19\r\n",
        "\r\n",
        "Demultiplex and quality filter (at Phred >= Q20) one lane of Illumina fastq data and write results to ./slout_q20. Store trimmed quality scores in addition to sequence data.: \r\n",
        " split_libraries_fastq.py -i lane1_read1.fastq.gz -b lane1_barcode.fastq.gz --rev_comp_mapping_barcodes -o slout_q20/ -m map.txt --store_qual_scores -q 19\r\n",
        "\r\n",
        "Demultiplex and quality filter (at Phred >= Q20) two lanes of Illumina fastq data and write results to ./slout_q20.: \r\n",
        " split_libraries_fastq.py -i lane1_read1.fastq.gz,lane2_read1.fastq.gz -b lane1_barcode.fastq.gz,lane2_barcode.fastq.gz --rev_comp_mapping_barcodes -o slout_q20/ -m map.txt,map.txt --store_qual_scores -q 19\r\n",
        "\r\n",
        "Quality filter (at Phred >= Q20) one non-multiplexed lane of Illumina fastq data and write results to ./slout_single_sample_q20.: \r\n",
        " split_libraries_fastq.py -i lane1_read1.fastq.gz --sample_id my.sample.1 -o slout_single_sample_q20/ -q 19 --barcode_type 'not-barcoded'\r\n",
        "\r\n",
        "Quality filter (at Phred >= Q20) two non-multiplexed lanes of Illumina fastq data with different samples in each and write results to ./slout_not_multiplexed_q20.: \r\n",
        " split_libraries_fastq.py -i lane1_read1.fastq.gz,lane2_read1.fastq.gz --sample_id my.sample.1,my.sample.2 -o slout_not_multiplexed_q20/ -q 19 --barcode_type 'not-barcoded'\r\n",
        "\r\n",
        "split_libraries_fastq.py: error: No filepaths match pattern/name '/scratch/jc33/run_1_fastqs/Undetermined_S0_L001_R1_001.fastq'. All patterns must be matched at least once.\r\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!print_qiime_config.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "System information\r\n",
        "==================\r\n",
        "         Platform:\tdarwin\r\n",
        "   Python version:\t2.7.5 (default, Mar  9 2014, 22:15:05)  [GCC 4.2.1 Compatible Apple LLVM 5.0 (clang-500.0.68)]\r\n",
        "Python executable:\t/Users/jc33/.virtualenvs/qiime-dev/bin/python\r\n",
        "\r\n",
        "Dependency versions\r\n",
        "===================\r\n",
        "                        NumPy version:\t1.9.0\r\n",
        "                        SciPy version:\t0.14.0\r\n",
        "                   matplotlib version:\t1.3.1\r\n",
        "                  biom-format version:\t2.1\r\n",
        "                         qcli version:\t0.1.0\r\n",
        "                         pyqi version:\t0.3.2\r\n",
        "                   scikit-bio version:\t0.1.4\r\n",
        "                QIIME library version:\t1.8.0-dev\r\n",
        "                 QIIME script version:\t1.8.0-dev\r\n",
        "        PyNAST version (if installed):\t1.2.2\r\n",
        "                      Emperor version:\t0.9.4-dev\r\n",
        "RDP Classifier version (if installed):\trdp_classifier-2.2.jar\r\n",
        "          Java version (if installed):\t1.6.0_65\r\n",
        "\r\n",
        "QIIME config values\r\n",
        "===================\r\n",
        "   template_alignment_lanemask_fp:\tNone\r\n",
        "     pynast_template_alignment_fp:\t/Users/jc33/dependencies/data/core_set_aligned.fasta.imputed\r\n",
        "                 seconds_to_sleep:\t2\r\n",
        "                     torque_queue:\tfriendlyq\r\n",
        "                    jobs_to_start:\t1\r\n",
        "                cloud_environment:\tFalse\r\n",
        "            denoiser_min_per_core:\t50\r\n",
        "                      working_dir:\tNone\r\n",
        "assign_taxonomy_id_to_taxonomy_fp:\t/Users/jc33/.virtualenvs/qiime/gg_13_5_otus/taxonomy/97_otu_taxonomy.txt\r\n",
        "                         temp_dir:\t/tmp/\r\n",
        "                      blastall_fp:\tblastall\r\n",
        "                     blastmat_dir:\tNone\r\n",
        "                    python_exe_fp:\tpython\r\n",
        "                         sc_queue:\tall.q\r\n",
        "                  cluster_jobs_fp:\tNone\r\n",
        "pynast_template_alignment_blastdb:\tNone\r\n",
        "assign_taxonomy_reference_seqs_fp:\t/Users/jc33/.virtualenvs/qiime/gg_13_5_otus/rep_set/97_otus.fasta\r\n",
        "      topiaryexplorer_project_dir:\tNone\r\n",
        "                qiime_scripts_dir:\t/Users/jc33/.virtualenvs/qiime/bin\r\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}