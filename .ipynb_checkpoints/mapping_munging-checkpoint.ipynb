{
 "metadata": {
  "name": "",
  "signature": "sha256:d2fafd0323ba25267bcf8eceedad96413998dfcd5e66dd9cfa214f75daa2fcb8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Initial steps to get the data into an otu table\n",
      "=====\n",
      "The first thing that needs to be done is to run split libraries. There are currently two datasets, one for period one, and one for periods two and three. \n",
      "\n",
      "All analysis in this notebook are done with qiime 1.8.0 unless otherwise noted"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from IPython.display import FileLinks, FileLink"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The code below is not currently working as I have changed names of things.\n",
      "---------------------------------------------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#this is the mapping file that I sent to Argonne to be sequenced\n",
      "#md5 2b7d92514e0f704030acc7b4b2d52744\n",
      "run_1_ids_to_be_run_df = pd.read_csv('../../files/mapping_files/first_run_maps/first_run_ids.txt', names=['#SampleID'], index_col='#SampleID')\n",
      "\n",
      "#These are what they sent back, They are not correct.\n",
      "#md5 ba24bf3aafc54d26a7b697fd0746d926\n",
      "argonne_map_df = pd.read_csv('../../files/mapping_files/first_run_maps/first_run_map_from_argonne.txt', sep='\\t', names=['#SampleID'])\n",
      "argonne_map_df.set_index('#SampleID')\n",
      "\n",
      "#finally we arrived at this mapping file through discussion and corrections which were provided from argonne. This is not currently correct\n",
      "#md5 b900ae4cc3f453797928421c95fc789e \n",
      "run_1_map_df = pd.read_csv('../../files/mapping_files/first_run_maps/office_map_barcode_data_only_corrected.txt', index_col='#SampleID', sep='\\t')\n",
      "\n",
      "\n",
      "san_diego_df = pd.read_csv('/Users/jc33/Dropbox/caporaso_lab/office_study/mapping_files/master/san_diego_map.txt', index_col='#SampleID', sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 150
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "san_diego_df.index.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 151,
       "text": [
        "array(['S1C.3.Ca.001', 'S1C.3.Ce.001', 'S1C.3.Dr.001', ..., 'S3W.2.Ca.041',\n",
        "       'S3W.2.Ce.041', 'S3W.2.Dr.041'], dtype=object)"
       ]
      }
     ],
     "prompt_number": 151
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(argonne_map_df.index.values) #== len(set(argonne_map_df.index.values))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 152,
       "text": [
        "769"
       ]
      }
     ],
     "prompt_number": 152
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Check to see if there are any ids that are not in the valid mapping file from San Diego, \n",
      "#these should have been added but weren't\n",
      "for i in run_1_map_df.index.values:\n",
      "    if i not in san_diego_df.index.values and i.startswith('S'):\n",
      "        print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "S1S.3.Dr.003\n"
       ]
      }
     ],
     "prompt_number": 153
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Figure out which office is missing\n",
      "for i in run_1_map_df.index.values:\n",
      "    if i[:2] + i[3:] == 'S1.3.Dr.003':\n",
      "        print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "S1C.3.Dr.003\n",
        "S1S.3.Dr.003\n",
        "S1F.3.Dr.003\n"
       ]
      }
     ],
     "prompt_number": 154
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in run_1_map_df.index.values:\n",
      "    if i not in run_1_ids_to_be_run_df.index.values:\n",
      "        print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "F32.3Dr.021\n",
        "blankswab1\n",
        "blankswab3\n",
        "blankswab2\n",
        "S1S.3.Dr.003\n",
        "F1W3.Dr.002\n",
        "S1F.2.Ce.003\n",
        "3C.3.Dr.020\n",
        "blankswab5\n",
        "blankswab4\n",
        "F3F.2.Dr.001\n",
        "F3C.3.Ca.003.1\n",
        "F2W.3.C.012\n"
       ]
      }
     ],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in run_1_map_df.index.values:\n",
      "    if i == 'F3C.3.Ca.001':\n",
      "        print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "F3C.3.Ca.001\n"
       ]
      }
     ],
     "prompt_number": 174
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'F3C.3.Dr.021'[:1] + 'F3C.3.Dr.021'[3:]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 167,
       "text": [
        "'F.3.Dr.021'"
       ]
      }
     ],
     "prompt_number": 167
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#rename some of these... This list is based on emails, and logic inference from missing sample ids.\n",
      "new_row_names = {'F1W3.Dr.002':'F1W.3.Dr.002',\n",
      "                 'S1S.3.Dr.003':'S1W.3.Dr.003', 'F32.3Dr.021':'F3W.3.Dr.021', \n",
      "                 'F2W.3.C.012':'F2W.3.Ca.012'}\n",
      "run_1_map_df.rename(index=new_row_names, inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 175
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in run_1_map_df.index.values:\n",
      "    if i not in run_1_ids_to_be_run_df.index.values:\n",
      "        print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "blankswab1\n",
        "blankswab3\n",
        "blankswab2\n",
        "S1F.2.Ce.003\n",
        "blankswab5\n",
        "blankswab4\n",
        "F3F.2.Dr.001\n"
       ]
      }
     ],
     "prompt_number": 176
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "run_1_map_df.drop(['3C.3.Dr.020', 'F3C.3.Ca.003.1'], inplace=True)\n",
      "#We have a mapping file! "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 178
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#write the mapping out to file\n",
      "run_1_map_df.to_csv('../../files/mapping_files/first_run_maps/office_map_barcode_data_only_corrected2.txt', sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 179
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!validate_mapping_file.py -m '../../files/mapping_files/first_run_maps/office_map_barcode_data_only_corrected2.txt' -o '../../files/mapping_files/first_run_maps/check_map'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Errors and/or warnings detected in mapping file.  Please check the log and html file for details.\r\n"
       ]
      }
     ],
     "prompt_number": 180
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FileLink('../../files/mapping_files/first_run_maps/check_map/office_map_barcode_data_only_corrected2.html')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<a href='../../files/mapping_files/first_run_maps/check_map/office_map_barcode_data_only_corrected2.html' target='_blank'>../../files/mapping_files/first_run_maps/check_map/office_map_barcode_data_only_corrected2.html</a><br>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 149,
       "text": [
        "/Users/jc33/google_drive/thesis/analysis/files/mapping_files/first_run_maps/check_map/office_map_barcode_data_only_corrected2.html"
       ]
      }
     ],
     "prompt_number": 149
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "F3C.3.Dr.021"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# there are ids in the list of ids to be sequenced that are not in the mapping file, this is a problem.\n",
      "first_run_ids = pd.read_csv('../../files/mapping_files/first_run_maps/first_run_ids.txt', names=['#SampleID'])\n",
      "mapping_file_df = pd.read_csv('../../files/mapping_files/master_period_1-2-3_map_5182014.txt', sep='\\t')\n",
      "argonne_map_df = pd.read_csv('../../files/mapping_files/first_run_maps/first_run_map_from_argonne.txt', sep='\\t', names=['#SampleID'])\n",
      "corrected_map_df = pd.read_csv('../../files/mapping_files/office_map_barcode_data_only_corrected.txt', sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "End first run mapping analysis\n",
      "===========================\n",
      "Begin second run mapping munging\n",
      "==============================="
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "flag_map = '/Users/jc33/google_drive/thesis/analysis/files/mapping_files/flagstaff_all_ids_no_barcodes_map.txt'\n",
      "toronto_map = '/Users/jc33/google_drive/thesis/analysis/files/mapping_files/toronto_all_ids_no_barcodes_map.txt'\n",
      "san_diego_map = '/Users/jc33/google_drive/thesis/analysis/files/mapping_files/sandiego_all_ids_no_barcodes_map.txt'\n",
      "all_cities = '/Users/jc33/google_drive/thesis/analysis/files/mapping_files/all_cities_and_samples_no_barcodes_no_metadata_map.txt'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "run_2_ids_to_be_run_df = pd.read_csv('../../files/mapping_files/second_run_maps/master_seq_ids.txt', names=['#SampleID'], index_col='#SampleID')\n",
      "corrected_run_two_map = pd.read_csv('../../files/mapping_files/second_run_maps/master_map_data_5_10_14_corrected.txt', sep='\\t', index_col='#SampleID')\n",
      "\n",
      "corrected_run_two_map58 = pd.read_csv('../../files/mapping_files/second_run_maps/John_Chase_MappingFile_5_8_14.txt', sep='\\t', index_col='#SampleID')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = 0 \n",
      "for i in corrected_run_two_map58.index.values:\n",
      "    if i not in run_2_ids_to_be_run_df.index.values:\n",
      "        print i\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "F2W.3.Dr.059_a\n",
        "F2W.3.Dr.059-b\n",
        "F1W.2.Dr.050\n",
        "F1F.2.Ce.050\n",
        "F1C.2.Ce.050\n",
        "F1W.2.Ca.050\n",
        "F1F.2.Dr.050\n",
        "F1C.2.Ca.050\n",
        "F1F.2.Ca.050\n",
        "F1C.2.Dr.050\n",
        "F1W.2.Ce.050\n",
        "F2F.2.Dr.050\n",
        "F2C.2.Ca.050\n",
        "F2W.2.Ca.050\n",
        "F2W.2.Dr.050\n",
        "F2C.2.Dr.050\n",
        "F2F.2.Ce.050\n",
        "F2C.2.Ce.050\n",
        "F2F.2.Ca.050\n",
        "F2W.2.Ce.050\n",
        "F3C.2.Ce.050\n",
        "F3F.2.Ca.050\n",
        "F3C.2.Dr.050\n",
        "F3W.2.Dr.050\n",
        "F3F.2.Ce.050\n",
        "F3C.2.Ca.050\n",
        "F3F.2.Dr.050\n",
        "F3W.2.Ce.050\n",
        "F3W.2.Ca.050\n",
        "F2W.3.Ca.041_b\n",
        "S1F.2.Dr.033\n",
        "S3W.3.Dr.024\n",
        "T2F.3.Dr.031_a\n",
        "T2F.3.Dr.031_b\n",
        "T2W.3.Ca.031_a\n",
        "T2W.3.Ca.031_b\n",
        "T1F.2.Dr.023\n",
        "T3W.2.Ca.023\n",
        "T1W.2.Ce.023\n",
        "T3F.2.Dr.023\n",
        "T1W.2.Ca.023\n",
        "T2C.2.Ca.023_a\n",
        "T2W.2.Ce.023\n",
        "T2W.2.Dr.023\n",
        "T1C.2.Dr.023\n",
        "T3F.2.Ce.023\n",
        "T2F.2.Ca.023\n",
        "T3C.2.Ce.023\n",
        "T1C.2.Ce.023\n",
        "T2C.2.Dr.023\n",
        "T3C.2.Dr.023\n",
        "T1W.2.Dr.023\n",
        "T2C.2.Ce.023\n",
        "T1F.2.Ce.023\n",
        "T3W.2.Ce.023\n",
        "T3W.2.Dr.023\n",
        "T2F.2.Ce.023\n",
        "T1F.2.Ca.023\n",
        "T2W.2.Ca.023\n",
        "T1C.2.Ca.023\n",
        "T3F.2.Ca.023\n",
        "T2F.2.Dr.023\n",
        "T2C.2.Ca.023_b\n",
        "T2C.2.Dr.050\n",
        "T2F.2.Ca.050\n",
        "T1C.2.Dr.050\n",
        "T3C.2.Ce.050\n",
        "T3F.2.Ca.050\n",
        "T2F.2.Ce.050\n",
        "T2F.2.Dr.050\n",
        "T3F.2.Ce.050\n",
        "T3F.2.Dr.050\n",
        "T3W.2.Ce.050\n",
        "T1W.2.Ca.050\n",
        "T1W.2.Ce.050\n",
        "T1C.2.Ce.050\n",
        "T1F.2.Dr.050\n",
        "T3C.2.Dr.050\n",
        "T3W.2.Dr.050\n",
        "T2W.2.Ca.050\n",
        "T2W.2.Dr.050\n",
        "T1C.2.Ca.050\n",
        "T3C.2.Ca.050\n",
        "T2C.2.Ce.050\n",
        "T1F.2.Ca.050\n",
        "T2W.2.Ce.050\n",
        "T1F.2.Ce.050\n",
        "T1W.2.Dr.050\n",
        "T3W.2.Ca.050\n",
        "T2C.2.Ca.050\n",
        "F2W.3.Ca.041_a\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following code is designed to add metadata to mapping files.\n",
      "================================================================\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First thing is to make sure the mapping files are formatted correctly.\n",
      "---------------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "first_run_df = pd.read_csv('/Users/jc33/google_drive/thesis/analysis/files/mapping_files/first_run_maps/first_run_corrected_no_metadata.txt', sep='\\t')\n",
      "second_run_df = pd.read_csv('/Users/jc33/google_drive/thesis/analysis/files/mapping_files/second_run_maps/second_run_corrected_map.txt', sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 276
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# I need to get the headers matching up\n",
      "second_run_df.columns = ['#SampleID', 'BarcodeSequence', 'LinkerPrimerSequence',\n",
      " 'TimeOfCollection', 'Cooler', 'Notes', 'WeekDay',\n",
      " 'DateOfCollection', 'City', 'Office', 'PlateLocation', 'Row',\n",
      " 'Surface', 'TimePoint', 'TimePointCategory', 'Description'] \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 277
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "combined_df = first_run_df.append(second_run_df)\n",
      "combined_df = combined_df.set_index('#SampleID')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 278
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cols = ['BarcodeSequence', 'LinkerPrimerSequence', 'DateOfCollection', 'TimeOfCollection', \n",
      "        'WeekDay', 'Notes', 'Cooler', 'Description'\n",
      "        ]\n",
      "\n",
      "combined_df = combined_df[cols]\n",
      "combined_df[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>BarcodeSequence</th>\n",
        "      <th>LinkerPrimerSequence</th>\n",
        "      <th>DateOfCollection</th>\n",
        "      <th>TimeOfCollection</th>\n",
        "      <th>WeekDay</th>\n",
        "      <th>Notes</th>\n",
        "      <th>Cooler</th>\n",
        "      <th>Description</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>#SampleID</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>S1F.3.Ca.023</th>\n",
        "      <td> ATGAATGCGTCC</td>\n",
        "      <td> CCGGACTACHVGGGTWTCTAAT</td>\n",
        "      <td> 7/10/2013</td>\n",
        "      <td> 16:30:00</td>\n",
        "      <td> NaN</td>\n",
        "      <td>                   JF</td>\n",
        "      <td> no_data</td>\n",
        "      <td> S1F.3.Ca.023</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>S1F.3.Ca.022</th>\n",
        "      <td> GGCCCAATATAA</td>\n",
        "      <td> CCGGACTACHVGGGTWTCTAAT</td>\n",
        "      <td>  7/8/2013</td>\n",
        "      <td> 14:50:00</td>\n",
        "      <td> NaN</td>\n",
        "      <td>                   PR</td>\n",
        "      <td> no_data</td>\n",
        "      <td> S1F.3.Ca.022</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>S1F.3.Ca.021</th>\n",
        "      <td> GTCCACTTGGAC</td>\n",
        "      <td> CCGGACTACHVGGGTWTCTAAT</td>\n",
        "      <td>  7/6/2013</td>\n",
        "      <td> 10:50:00</td>\n",
        "      <td> NaN</td>\n",
        "      <td>                   JF</td>\n",
        "      <td> no_data</td>\n",
        "      <td> S1F.3.Ca.021</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>S2C.3.Dr.003</th>\n",
        "      <td> ATCCTACGAGCA</td>\n",
        "      <td> CCGGACTACHVGGGTWTCTAAT</td>\n",
        "      <td> 5/31/2013</td>\n",
        "      <td> 12:30:00</td>\n",
        "      <td> NaN</td>\n",
        "      <td>     Time Zero, row 3</td>\n",
        "      <td> no_data</td>\n",
        "      <td> S2C.3.Dr.003</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>S2C.3.Dr.005</th>\n",
        "      <td> GATCAACCCACA</td>\n",
        "      <td> CCGGACTACHVGGGTWTCTAAT</td>\n",
        "      <td>  6/4/2013</td>\n",
        "      <td> 15:10:00</td>\n",
        "      <td> NaN</td>\n",
        "      <td> Training Pascal _PR_</td>\n",
        "      <td> no_data</td>\n",
        "      <td> S2C.3.Dr.005</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 8 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 279,
       "text": [
        "             BarcodeSequence    LinkerPrimerSequence DateOfCollection  \\\n",
        "#SampleID                                                               \n",
        "S1F.3.Ca.023    ATGAATGCGTCC  CCGGACTACHVGGGTWTCTAAT        7/10/2013   \n",
        "S1F.3.Ca.022    GGCCCAATATAA  CCGGACTACHVGGGTWTCTAAT         7/8/2013   \n",
        "S1F.3.Ca.021    GTCCACTTGGAC  CCGGACTACHVGGGTWTCTAAT         7/6/2013   \n",
        "S2C.3.Dr.003    ATCCTACGAGCA  CCGGACTACHVGGGTWTCTAAT        5/31/2013   \n",
        "S2C.3.Dr.005    GATCAACCCACA  CCGGACTACHVGGGTWTCTAAT         6/4/2013   \n",
        "\n",
        "             TimeOfCollection WeekDay                 Notes   Cooler  \\\n",
        "#SampleID                                                              \n",
        "S1F.3.Ca.023         16:30:00     NaN                    JF  no_data   \n",
        "S1F.3.Ca.022         14:50:00     NaN                    PR  no_data   \n",
        "S1F.3.Ca.021         10:50:00     NaN                    JF  no_data   \n",
        "S2C.3.Dr.003         12:30:00     NaN      Time Zero, row 3  no_data   \n",
        "S2C.3.Dr.005         15:10:00     NaN  Training Pascal _PR_  no_data   \n",
        "\n",
        "               Description  \n",
        "#SampleID                   \n",
        "S1F.3.Ca.023  S1F.3.Ca.023  \n",
        "S1F.3.Ca.022  S1F.3.Ca.022  \n",
        "S1F.3.Ca.021  S1F.3.Ca.021  \n",
        "S2C.3.Dr.003  S2C.3.Dr.003  \n",
        "S2C.3.Dr.005  S2C.3.Dr.005  \n",
        "\n",
        "[5 rows x 8 columns]"
       ]
      }
     ],
     "prompt_number": 279
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We now have a combined mapping file that only contains columns with information that is NOT inherent in the ID"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Get the metadata that we can from the city maps\n",
      "------------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "flagstaff_df = pd.read_csv('/Users/jc33/google_drive/thesis/analysis/files/mapping_files/flagstaff_all_ids_no_barcodes_map.txt', sep='\\t', index_col='#SampleID')\n",
      "san_diego_df = pd.read_csv('/Users/jc33/google_drive/thesis/analysis/files/mapping_files/sandiego_all_ids_no_barcodes_map.txt', sep='\\t', index_col='#SampleID')\n",
      "toronto_df = pd.read_csv('/Users/jc33/google_drive/thesis/analysis/files/mapping_files/toronto_all_ids_no_barcodes_map.txt', sep='\\t', index_col='#SampleID')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 280
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "flagstaff_df.columns = ['DateOfCollection', 'TimeOfCollection', 'Notes', 'WeekDay']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 281
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def correct_time(time):\n",
      "    time = str(time)\n",
      "    try:\n",
      "        int(time[0])\n",
      "    except: \n",
      "        time = 'no data'\n",
      "    else:\n",
      "        if ':' in time:\n",
      "            pass\n",
      "        else:\n",
      "            time = time[:-2] + ':' + time[-2:] + ':00'\n",
      "    return time\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 282
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "flagstaff_df['TimeOfCollection'] = flagstaff_df['TimeOfCollection'].apply(correct_time)\n",
      "flagstaff_df['Cooler'] = np.nan"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 283
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "san_diego_df.columns = ['DateOfCollection', 'TimeOfCollection', 'Notes', 'WeekDay']\n",
      "san_diego_df['Cooler'] = np.nan"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 284
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "toronto_df.columns = ['DateOfCollection', 'TimeOfCollection', 'Notes', 'Cooler', 'WeekDay']\n",
      "toronto_df = toronto_df[['DateOfCollection', 'TimeOfCollection', 'Notes','WeekDay', 'Cooler']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 285
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "flag_toront_no_barcodes_df = flagstaff_df.append(toronto_df)\n",
      "all_cities_no_barcodes_df = flag_toront_no_barcodes_df.append(san_diego_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 286
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_cities_no_barcodes_df.ix[['S1F.3.Ca.022', 'S1C.3.Ce.001']]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>DateOfCollection</th>\n",
        "      <th>TimeOfCollection</th>\n",
        "      <th>Notes</th>\n",
        "      <th>WeekDay</th>\n",
        "      <th>Cooler</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>#SampleID</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>S1F.3.Ca.022</th>\n",
        "      <td>  7/8/2013</td>\n",
        "      <td>          14:50:00</td>\n",
        "      <td>                PR</td>\n",
        "      <td>    Monday</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>S1C.3.Ce.001</th>\n",
        "      <td> 5/29/2013</td>\n",
        "      <td> Time not recorded</td>\n",
        "      <td> pre-sterilization</td>\n",
        "      <td> Wednesday</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>2 rows \u00d7 5 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 287,
       "text": [
        "             DateOfCollection   TimeOfCollection              Notes  \\\n",
        "#SampleID                                                             \n",
        "S1F.3.Ca.022         7/8/2013           14:50:00                 PR   \n",
        "S1C.3.Ce.001        5/29/2013  Time not recorded  pre-sterilization   \n",
        "\n",
        "                WeekDay  Cooler  \n",
        "#SampleID                        \n",
        "S1F.3.Ca.022     Monday     NaN  \n",
        "S1C.3.Ce.001  Wednesday     NaN  \n",
        "\n",
        "[2 rows x 5 columns]"
       ]
      }
     ],
     "prompt_number": 287
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# # print combined_df.columns\n",
      "print len(combined_df.index)\n",
      "print len(all_cities_no_barcodes_df.ix[combined_df.index])\n",
      "# this = all_cities_no_barcodes_df.ix[combined_df.index]['TimeOfCollection']\n",
      "# print len(this)\n",
      "# print len(combined_df['TimeOfCollection'])\n",
      "# for i in this:\n",
      "#     print i \n",
      "print len(all_cities_no_barcodes_df.ix[combined_df.index].index)\n",
      "for i in all_cities_no_barcodes_df.ix[combined_df.index].index:\n",
      "    if i not in combined_df.index:\n",
      "        print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1605\n",
        "1606\n",
        "1606\n"
       ]
      }
     ],
     "prompt_number": 288
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import collections\n",
      "print [x for x, y in collections.Counter(all_cities_no_barcodes_df.ix[combined_df.index].index).items() if y > 1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['T2C.3.Ca.059']\n"
       ]
      }
     ],
     "prompt_number": 289
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}